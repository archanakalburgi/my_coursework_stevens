{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Word Vector (a.k.a Word Embedding) </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Word2Vector\n",
    " - Vector representation of words (i.e. word vectors) learned using neural network\n",
    "   - e.g. \"apple\" : [0.35, -0.2, 0.4, ...], 'mongo':  [0.32, -0.18, 0.5, ...]\n",
    "   - Interesting properties of word vectors:\n",
    "    * **Words with similar semantics have close word vectors**\n",
    "    <img src=\"https://www.kdnuggets.com/images/cartoon-espresso-word2vec.jpg\" width=\"50%\">\n",
    "    https://www.kdnuggets.com/2017/04/cartoon-word2vec-espresso-cappuccino.html\n",
    "    * **Composition**: e.g. vector(\"woman\")+vector(\"king\")-vector('man') $\\approx$ vector(\"queen\")\n",
    " - Models:\n",
    "   - **CBOW** (Continuous Bag of Words): Predict a target word based on context\n",
    "     - e.g. the fox jumped over the lazy dog\n",
    "     - Assuming symmetric context with window size 3, this sentence can create training samples: \n",
    "       - ([-, fox], the) \n",
    "       - ([the, jumped], fox) \n",
    "       - ([fox, over], jumped)\n",
    "       - ([jumped, the], over) \n",
    "       - ...\n",
    "       \n",
    "       <img src=\"cbow.png\" width=\"50%\">\n",
    "       source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "   - **Skip Gram**: predict context based on target words\n",
    "   \n",
    "        <img src=\"skip_gram.png\" width=\"50%\">\n",
    "        source: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up interactive shell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a little longer and more detailed than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Only Michelle Branch save this album!!!!All gu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A surprisingly good book, given its inherently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>This is a wonderful, quiet and relaxing CD tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The lights that I received are absolutely not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      2  This is a little longer and more detailed than...\n",
       "1      1  Only Michelle Branch save this album!!!!All gu...\n",
       "2      2  A surprisingly good book, given its inherently...\n",
       "3      2  This is a wonderful, quiet and relaxing CD tha...\n",
       "4      1  The lights that I received are absolutely not ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'little', 'longer', 'and', 'more', 'detailed', 'than', 'the', 'first', 'two', 'books', 'in', 'the', 'series', 'however', 'have', 'enjoyed', 'each', 'new', 'aspect', 'of', 'the', 'exciting', 'fantasy', 'universe'], ['only', 'michelle', 'branch', 'save', 'this', 'album', 'all', 'guys', 'play', 'along', 'with', 'unenthusiastic', 'beat', 'even', 'karl']]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.1 Train your word vector\n",
    "\n",
    "import pandas as pd\n",
    "import nltk,string\n",
    "\n",
    "# Load data\n",
    "data=pd.read_csv('amazon_review_large.csv')\n",
    "data.columns=['label','text']\n",
    "data.head()\n",
    "\n",
    "# tokenize each document into a list of unigrams\n",
    "# strip punctuations and leading/trailing spaces from unigrams\n",
    "# only unigrams with 2 or more characters are taken\n",
    "sentences=[ [token.strip(string.punctuation).strip() \\\n",
    "             for token in nltk.word_tokenize(doc.lower()) \\\n",
    "                 if token not in string.punctuation and \\\n",
    "                 len(token.strip(string.punctuation).strip())>=2]\\\n",
    "             for doc in data[\"text\"]]\n",
    "print(sentences[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 21:12:51,359 : INFO : collecting all words and their counts\n",
      "2021-11-26 21:12:51,361 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-11-26 21:12:51,492 : INFO : PROGRESS: at sentence #10000, processed 711991 words, keeping 36968 word types\n",
      "2021-11-26 21:12:51,657 : INFO : collected 55241 word types from a corpus of 1424289 raw words and 20000 sentences\n",
      "2021-11-26 21:12:51,658 : INFO : Creating a fresh vocabulary\n",
      "2021-11-26 21:12:51,729 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12133 unique words (21.96375880233884%% of original 55241, drops 43108)', 'datetime': '2021-11-26T21:12:51.729906', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-11-26 21:12:51,730 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 1361999 word corpus (95.62658982832838%% of original 1424289, drops 62290)', 'datetime': '2021-11-26T21:12:51.730753', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-11-26 21:12:51,810 : INFO : deleting the raw counts dictionary of 55241 items\n",
      "2021-11-26 21:12:51,812 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2021-11-26 21:12:51,813 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1015588.3176218013 word corpus (74.6%% of prior 1361999)', 'datetime': '2021-11-26T21:12:51.813845', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2021-11-26 21:12:51,946 : INFO : estimated required memory for 12133 words and 200 dimensions: 25479300 bytes\n",
      "2021-11-26 21:12:51,946 : INFO : resetting layer weights\n",
      "2021-11-26 21:12:51,959 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-26T21:12:51.959843', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2021-11-26 21:12:51,960 : INFO : Word2Vec lifecycle event {'msg': 'training model with 4 workers on 12133 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2021-11-26T21:12:51.960813', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-11-26 21:12:52,586 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-26 21:12:52,589 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-26 21:12:52,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-26 21:12:52,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-26 21:12:52,599 : INFO : EPOCH - 1 : training on 1424289 raw words (1015739 effective words) took 0.6s, 1608440 effective words/s\n",
      "2021-11-26 21:12:53,295 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-26 21:12:53,298 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-26 21:12:53,303 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-26 21:12:53,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-26 21:12:53,309 : INFO : EPOCH - 2 : training on 1424289 raw words (1015657 effective words) took 0.7s, 1444751 effective words/s\n",
      "2021-11-26 21:12:53,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-26 21:12:53,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-26 21:12:53,927 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-26 21:12:53,932 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-26 21:12:53,933 : INFO : EPOCH - 3 : training on 1424289 raw words (1015613 effective words) took 0.6s, 1637877 effective words/s\n",
      "2021-11-26 21:12:54,596 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-26 21:12:54,600 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-26 21:12:54,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-26 21:12:54,607 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-26 21:12:54,608 : INFO : EPOCH - 4 : training on 1424289 raw words (1015627 effective words) took 0.7s, 1522086 effective words/s\n",
      "2021-11-26 21:12:55,217 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-11-26 21:12:55,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-11-26 21:12:55,227 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-11-26 21:12:55,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-11-26 21:12:55,230 : INFO : EPOCH - 5 : training on 1424289 raw words (1015549 effective words) took 0.6s, 1646996 effective words/s\n",
      "2021-11-26 21:12:55,230 : INFO : Word2Vec lifecycle event {'msg': 'training on 7121445 raw words (5078185 effective words) took 3.3s, 1553396 effective words/s', 'datetime': '2021-11-26T21:12:55.230655', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'train'}\n",
      "2021-11-26 21:12:55,231 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=12133, vector_size=200, alpha=0.025)', 'datetime': '2021-11-26T21:12:55.231154', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# Train your own word vectors using gensim\n",
    "\n",
    "# gensim.models is the package for word2vec\n",
    "# check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "# for detailed description\n",
    "\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# print out tracking information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \\\n",
    "                    level=logging.INFO)\n",
    "\n",
    "# min_count: words with total frequency lower than this are ignored\n",
    "# size: the dimension of word vector\n",
    "# window: context window, i.e. the maximum distance \n",
    "#         between the current and predicted word \n",
    "#         within a sentence (i.e. the length of ngrams)\n",
    "# workers: # of parallel threads in training\n",
    "# for other parameters, check https://radimrehurek.com/gensim/models/word2vec.html\n",
    "wv_model = word2vec.Word2Vec(sentences, \\\n",
    "            min_count=5, vector_size=200, \\\n",
    "            window=5, workers=4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('band', 0.7466944456100464),\n",
       " ('metal', 0.7309845089912415),\n",
       " ('production', 0.7275912165641785),\n",
       " ('vocals', 0.7178143858909607),\n",
       " ('beats', 0.7157869338989258)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 words similar to word 'sound' but not relevant to 'film'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pop', 0.7688503265380859),\n",
       " ('rock', 0.7571867108345032),\n",
       " ('guitar', 0.7289978265762329),\n",
       " ('songs', 0.7192723751068115),\n",
       " ('invisible', 0.7177398800849915)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'film':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92379814"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'movie' and 'city':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.036855552"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word does not match with others in the list of ['sound', 'music', 'graphics', 'actor', 'book']:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'book'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector for 'movie':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.802832  ,  0.24956171, -0.11756705,  0.04693254, -1.5093597 ,\n",
       "        0.5086073 ,  0.3910569 , -0.89214   ,  0.23388013, -1.2573065 ,\n",
       "        0.6647229 ,  1.7413628 ,  0.81334066, -0.9406785 , -1.178873  ,\n",
       "        0.68965447,  1.0267875 , -1.4296671 , -1.1222117 , -1.606071  ,\n",
       "        1.7382059 ,  0.56719065,  0.04122837,  0.22017027, -0.3461662 ,\n",
       "       -0.13749823, -0.9189834 , -1.0497375 ,  0.7365495 ,  0.09684153,\n",
       "        0.30657044,  0.7274297 ,  0.5823868 ,  0.03434692, -1.6505245 ,\n",
       "        2.875775  , -1.5738666 , -0.4178427 , -1.1819825 , -0.4639121 ,\n",
       "        0.55049515, -1.1630489 ,  0.54714614, -0.92406774,  0.7725745 ,\n",
       "        0.2697898 , -0.9988751 , -0.14581019, -0.04652194,  0.31032822,\n",
       "        0.29798335, -0.36748606,  0.33740562, -0.04714237, -1.3902302 ,\n",
       "       -1.067852  , -0.7876221 , -2.2594395 , -1.5850363 ,  1.1617929 ,\n",
       "        1.4588189 , -0.04304981,  0.71149564, -0.55700463, -2.5268452 ,\n",
       "       -1.3418169 ,  0.26387188,  0.10013806, -0.73470455,  0.39770612,\n",
       "        0.5065341 ,  1.4594344 ,  0.95209855,  0.44258544,  0.19725145,\n",
       "       -1.0049571 ,  2.3528962 ,  0.01366105, -1.6356779 ,  0.173993  ,\n",
       "       -0.07093949, -0.82312334, -1.2965604 , -0.14975081, -0.53450626,\n",
       "       -0.03705219,  1.5994643 ,  0.6313663 , -1.0390366 ,  0.30132937,\n",
       "        0.23536944,  0.8956761 ,  0.2444061 , -0.11600939, -0.52704763,\n",
       "        0.67840564, -0.8954986 , -0.82062966,  0.4964672 ,  1.4842579 ,\n",
       "        0.42322704, -0.4093063 ,  1.4624926 , -1.8591985 ,  1.4679621 ,\n",
       "        0.48699275, -0.3030638 , -1.3160024 , -0.13226482,  1.3639237 ,\n",
       "        0.520138  , -1.5730096 ,  0.6063167 , -0.77484006,  0.75499636,\n",
       "        0.47844356,  2.207294  , -0.25039652,  0.1397654 ,  0.55232614,\n",
       "        0.089279  ,  1.3653619 ,  1.2556955 ,  1.4863821 , -1.0511409 ,\n",
       "        0.64893514,  0.8396899 ,  0.9816944 ,  0.3234426 , -0.1524925 ,\n",
       "        1.8199936 , -0.5520708 ,  0.3710983 , -1.0201043 ,  0.62848455,\n",
       "       -1.2944022 ,  0.6626879 ,  0.8038365 , -0.42785102, -0.16223024,\n",
       "       -0.11335327,  0.27161136, -0.12791432, -1.5311518 , -1.8293543 ,\n",
       "       -0.39491704, -0.5337843 ,  0.7758201 ,  0.57505876, -1.4777431 ,\n",
       "       -0.04070774, -1.086612  ,  1.6036246 , -0.9545042 ,  0.7474546 ,\n",
       "        0.30606785,  0.35414743,  2.3398755 , -0.55985886, -0.18651076,\n",
       "        0.4732579 , -0.29538503, -1.6896963 ,  2.8892956 ,  0.4342756 ,\n",
       "        1.3679063 , -0.61184824,  1.0790496 ,  0.39981142, -0.9822273 ,\n",
       "       -1.0549433 ,  1.2320508 , -0.06196262, -1.6105052 , -1.425723  ,\n",
       "        0.32382235,  0.00531442,  1.7085718 ,  0.79473275, -0.21838301,\n",
       "       -1.1002159 , -1.4858607 , -0.05873797,  0.3012048 ,  0.69434536,\n",
       "        0.41379994, -0.8324041 , -0.5401535 ,  0.5301314 ,  0.55243605,\n",
       "       -1.2018309 , -0.84638935, -0.20272726, -1.0722165 ,  1.5638922 ,\n",
       "        0.95433086, -0.37784982, -0.03345486, -1.0710598 ,  0.26041618],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test word2vec model\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound'\")\n",
    "wv_model.wv.most_similar('sound', topn=5)\n",
    "\n",
    "print(\"Top 5 words similar to word 'sound' but not relevant to 'film'\")\n",
    "wv_model.wv.most_similar(positive=['sound','music'], \\\n",
    "                         negative=['film'], topn=5)\n",
    "\n",
    "print(\"Similarity between 'movie' and 'film':\")\n",
    "wv_model.wv.similarity('movie','film') \n",
    "\n",
    "print(\"Similarity between 'movie' and 'city':\")\n",
    "wv_model.wv.similarity('movie','city') \n",
    "\n",
    "print(\"Word does not match with others in the list of \\\n",
    "['sound', 'music', 'graphics', 'actor', 'book']:\")\n",
    "wv_model.wv.doesnt_match([\"sound\", \"music\", \\\n",
    "                          \"graphics\", \"actor\", \"book\"])\n",
    "\n",
    "print(\"Word vector for 'movie':\")\n",
    "wv_model.wv['movie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Pretrained Word Vectors\n",
    "- Google published pre-trained 300-dimensional vectors for 3 million words and phrases that were trained on Google News dataset (about 100 billion words)(https://code.google.com/archive/p/word2vec/)\n",
    "- GloVe (Global Vectors for Word Representation): Pretained word vectors from different data sources provided by Standford https://nlp.stanford.edu/projects/glove/\n",
    "- FastText by Facebook https://github.com/facebookresearch/fastText/blob/master/pretrained-vectors.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-26 21:16:27,886 : INFO : loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "2021-11-26 21:17:01,517 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-11-26T21:17:01.517006', 'gensim': '4.1.2', 'python': '3.7.6 (default, Jan  8 2020, 13:42:34) \\n[Clang 4.0.1 (tags/RELEASE_401/final)]', 'platform': 'Darwin-20.6.0-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1.2: Use pretrained word vectors\n",
    "\n",
    "# download the bin file for pretrained word vectors\n",
    "# from above links, e.g. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "# Warning: the bin file is very big (over 2G)\n",
    "# You need a powerful machine to load it\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.\\\n",
    "load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.4827326238155365),\n",
       " ('queens', 0.466781347990036),\n",
       " ('kumaris', 0.4653734564781189),\n",
       " ('kings', 0.4558638632297516),\n",
       " ('womens', 0.422832190990448),\n",
       " ('princes', 0.4176960587501526),\n",
       " ('Al_Anqari', 0.41725507378578186),\n",
       " ('concubines', 0.4011078476905823),\n",
       " ('monarch', 0.3962482810020447),\n",
       " ('monarchy', 0.39430150389671326)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['women','king'], \\\n",
    "                      negative='man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. How to use word vectors in classification?\n",
    "\n",
    "`Convolutional Neural Network`\n",
    "<img src=\"CNN.png\" width =\"100%\">\n",
    "\n",
    "`Recurrent Neural Network`\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/graviraja/100-Days-of-NLP/master/assets/images/applications/sentiment/simple.gif\" width = \"90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.kdnuggets.com/images/cartoon-machine-learning-vacation.jpg\" width='60%'>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
