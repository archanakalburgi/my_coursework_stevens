{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PCA.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1VefSksipeEsF5SXGnQxXxFTrnRyZt-UI","authorship_tag":"ABX9TyOwVURFv/wTIv10BIYoRVID"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mLa6bmwTzU0H"},"source":["**Name : Archana Kalburgi**\n","\n","**CWID : 10469491**\n","\n","**Solution to Question 1**"]},{"cell_type":"markdown","metadata":{"id":"2Qzu8jc1wNw3"},"source":["How did I select the Principal Components:\n","\n","- Calculate the Covariance matrix\n","\n","- Compute the Eigenvalues and Eigenvectors for the calculated Covariance matrix.\n","\n","- The Eigenvectors Orthogonal to each other and each vector represents a principal axis.\n","\n","- A Higher Eigenvalue corresponds to a higher variability.\n","\n","- Therefore, the principal axis with the higher Eigenvalue will be an axis capturing higher variability in the data.\n","\n","- Sort the Eigenvalues in the descending order along with their corresponding Eigenvector.\n","\n","- Arranging Eigenvectors in descending order of their Eigenvalue will automatically arrange the principal component in descending order of their variability.\n","\n","- Hence the first column in the rearranged Eigen vector-matrix will be a principal component that captures the highest variability."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433},"id":"uX9XXJxCwFzb","executionInfo":{"status":"ok","timestamp":1620757174171,"user_tz":240,"elapsed":362,"user":{"displayName":"Archana Kalburgi","photoUrl":"","userId":"07335954375421111860"}},"outputId":"666211db-12db-4416-bb20-1d508a0642f2"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","df = pd.read_csv(\"/content/drive/MyDrive/ML_Assignments/ML_Assign_test/pima-indians-diabetes.csv\")\n","\n","X = df.iloc[:, 0:8].to_numpy()\n","\n","X_meaned = X - np.mean(X, axis=0)\n","covariance = np.cov(X_meaned, rowvar=False)\n","evalue, evector = np.linalg.eigh(covariance)\n","\n","sorted_idx = np.argsort(evalue)[::-1]\n","sorted_evalues = evalue[sorted_idx]\n","sorted_evectors = evector[:, sorted_idx]\n","\n","pca = sorted_evectors[:, 0:3]\n","\n","X_reduced = np.dot(pca.transpose(), X_meaned.transpose()).transpose()\n","\n","target = df.iloc[:, 8]\n","\n","ddf = pd.DataFrame(X_reduced, columns = ['PC1', 'PC2', 'PC3'])\n","\n","df_with_class = pd.concat([ddf, pd.DataFrame(target)], axis= 1)\n","df_with_class"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PC1</th>\n","      <th>PC2</th>\n","      <th>PC3</th>\n","      <th>Class variable</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>75.714655</td>\n","      <td>-35.950783</td>\n","      <td>7.260789</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>82.358268</td>\n","      <td>28.908213</td>\n","      <td>5.496671</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>74.630643</td>\n","      <td>-67.906496</td>\n","      <td>-19.461808</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-11.077423</td>\n","      <td>34.898486</td>\n","      <td>0.053018</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-89.743788</td>\n","      <td>-2.746937</td>\n","      <td>-25.212859</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>763</th>\n","      <td>-99.237881</td>\n","      <td>25.080927</td>\n","      <td>19.534825</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>764</th>\n","      <td>78.641239</td>\n","      <td>-7.688010</td>\n","      <td>4.137227</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>765</th>\n","      <td>-32.113198</td>\n","      <td>3.376665</td>\n","      <td>1.587864</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>766</th>\n","      <td>80.214494</td>\n","      <td>-14.186020</td>\n","      <td>-12.351264</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>767</th>\n","      <td>81.308150</td>\n","      <td>21.621496</td>\n","      <td>8.152768</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>768 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["           PC1        PC2        PC3  Class variable\n","0    75.714655 -35.950783   7.260789               1\n","1    82.358268  28.908213   5.496671               0\n","2    74.630643 -67.906496 -19.461808               1\n","3   -11.077423  34.898486   0.053018               0\n","4   -89.743788  -2.746937 -25.212859               1\n","..         ...        ...        ...             ...\n","763 -99.237881  25.080927  19.534825               0\n","764  78.641239  -7.688010   4.137227               0\n","765 -32.113198   3.376665   1.587864               0\n","766  80.214494 -14.186020 -12.351264               1\n","767  81.308150  21.621496   8.152768               0\n","\n","[768 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"5aUc0fACwiq2"},"source":["# Train a classifier using MLE after the data have been projected.\n","\n","def noramal_eq(xi, mu, sigma_inv, scalar):\n","  pp = (-1/2)*np.dot(np.matmul(xi - mu, sigma_inv), xi - mu)\n","  return scalar * (np.e**pp)\n","\n","# calculating mean, sigma, sigma_inverse, scalar\n","def components(x):\n","  mu = np.mean(x, axis=0)\n","  sigma = np.cov(x, rowvar=False)\n","  sigma_inv = np.linalg.inv(sigma)\n","  scalar = 1/np.sqrt(((2*np.pi)**x.shape[1])*np.linalg.det(sigma))\n","  return (mu, sigma_inv, scalar)\n","\n","# computing likelihood\n","def likelihood(x, mu, sigma_inv, scalar):\n","  return [noramal_eq(x, mu, sigma_inv, scalar) for x in range(x.shape[0])]\n","\n","# computing the accuracy \n","def predit(train_x, train_y, test_x, test_y):\n","  # compute train accuracy(on train data)\n","  mu0, sigma_inv0, scalar0 = components(train_x)\n","  l0 = likelihood(train_x, mu0, sigma_inv0, scalar0 )\n","  mu1, sigma_inv1, scalar1 = components(train_x)\n","  l1 = likelihood(train_x, mu1, sigma_inv1, scalar1)\n","\n","  predicted_y = np.array([1 if ll1 > ll0 else 0 for (ll0, ll1) in zip(l0, l1)])\n","  train_n_correct = sum([1 if predicted_y[i] == train_y[i] else 0 for i in range(train_y.shape[0])])\n","  \n","  # compute test accuracy (on test data)\n","  tl_0 = likelihood(test_x, mu0, sigma_inv0, scalar0 )\n","  tl_1 = likelihood(test_x, mu1, sigma_inv1, scalar1 )\n","\n","  predited_test_y = np.array([1 if ll1 > ll0 else 0 for (ll0, ll1) in zip(tl_0, tl_1)])\n","  test_n_correct = sum([1 if predicted_y[i] == test_y[i] else 0 for i in range(test_y.shape[0])])\n","\n","  return (train_n_correct / train_y.shape[0], test_n_correct / test_y.shape[0]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mgj5nZpgwoKi","executionInfo":{"status":"ok","timestamp":1620757288503,"user_tz":240,"elapsed":475,"user":{"displayName":"Archana Kalburgi","photoUrl":"","userId":"07335954375421111860"}},"outputId":"e57d6d6a-ca67-4a79-ddeb-eec29a058115"},"source":["train_10scores = []\n","test_10scores = []\n","for i in range(1,11):\n","    print(\"----------------------------------------\")\n","    (x_train, x_test, y_train, y_test) = train_test_split(df_with_class, df_with_class.iloc[:,3], train_size=0.5)\n","    train_score, test_score = predit(x_train.iloc[:,0:3].to_numpy(), y_train.to_numpy(), x_test.iloc[:,0:3].to_numpy(), y_test.to_numpy())\n","    np.array(train_10scores.append(train_score))\n","    np.array(test_10scores.append(test_score))\n","    print(f\"Train Score is {train_score}\")\n","    print(f\"Test Score is {test_score}\") \n","\n","# printing out the mean and standard deviation of all the 10 accuracy scores of train and test data \n","print(\"-------------------------------------------------\")\n","print(\"\\n\")\n","# print(f\"Mean of the accuracies for train data = {np.mean(train_10scores)}\")\n","print(f\"Average classification accuracy over 10 runs = {round(np.mean(test_10scores),4)}\") \n","print(\"\\n\")\n","print(f\"Three principal components selected are:\")\n","print(\"\\n\")\n","print(pca.transpose()) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------\n","Train Score is 0.6744791666666666\n","Test Score is 0.6276041666666666\n","----------------------------------------\n","Train Score is 0.671875\n","Test Score is 0.6302083333333334\n","----------------------------------------\n","Train Score is 0.65625\n","Test Score is 0.6458333333333334\n","----------------------------------------\n","Train Score is 0.6380208333333334\n","Test Score is 0.6640625\n","----------------------------------------\n","Train Score is 0.640625\n","Test Score is 0.6614583333333334\n","----------------------------------------\n","Train Score is 0.6432291666666666\n","Test Score is 0.6588541666666666\n","----------------------------------------\n","Train Score is 0.6536458333333334\n","Test Score is 0.6484375\n","----------------------------------------\n","Train Score is 0.6796875\n","Test Score is 0.6223958333333334\n","----------------------------------------\n","Train Score is 0.6510416666666666\n","Test Score is 0.6510416666666666\n","----------------------------------------\n","Train Score is 0.6614583333333334\n","Test Score is 0.640625\n","-------------------------------------------------\n","\n","\n","Average classification accuracy over 10 runs = 0.64505\n","\n","\n","Three principal components selected are:\n","\n","\n","[[ 2.02176587e-03 -9.78115765e-02 -1.60930503e-02 -6.07566861e-02\n","  -9.93110844e-01 -1.40108085e-02 -5.37167919e-04  3.56474430e-03]\n"," [-2.26488861e-02 -9.72210040e-01 -1.41909330e-01  5.78614699e-02\n","   9.46266913e-02 -4.69729766e-02 -8.16804621e-04 -1.40168181e-01]\n"," [ 2.24649003e-02 -1.43428710e-01  9.22467192e-01  3.07013055e-01\n","  -2.09773019e-02  1.32444542e-01  6.39983017e-04  1.25454310e-01]]\n"],"name":"stdout"}]}]}